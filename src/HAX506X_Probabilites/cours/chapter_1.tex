\section{Espaces probabilisés}\label{subsec:1}
%\addcontentsline{toc}{subsection}{\nameref{subsec:1}}


\subsection{Probabilité}\label{subsubsec:1-1}
\setcounter{subsection}{0}
%\addcontentsline{toc}{subsubsection}{\nameref{subsubsec:1}}
\begin{definition}
    Soit \((\Omega, \scr F)\) un espace mesurable. Une
    \defemph{mesure} sur \((\Omega, \scr F)\) est une application
    \begin{equation*}
        \begin{aligned}
            \mu\colon \scr F &\to \ff{0,+\infty}\\
            A &\mapsto \mu(A)
        \end{aligned}
    \end{equation*}
    qui vérifie les propriétés suivantes:
    \begin{enumerate}
        \item \(\mu(\emptyset) = 0\)
        \item \(\mu\) est \(\sigma\)-additive, c'est-à-dire que pour
        toute suite \({(A_n)}_{n\in\N}\) d'éléments 2 à 2
        disjoints de \(\scr F\), on a
        \begin{equation*}
            \mu\left(\bigcup_{n\in\N}A_n\right) = \sum_{n\in\N}\mu(A_n)
        \end{equation*}
    \end{enumerate}

    On dit alors que \((\Omega, \scr F,\mu)\) est un \defemph{espace
    mesuré}.

    Si de plus \(\mu(\Omega) = 1\), on dit que \((\Omega, \scr F,\mu)\)
    est un \defemph{espace probabilisé} et \(\mu\) est une \defemph{probabilité}.

    On notera alors \(\mu = \bb P\).
\end{definition}

\begin{remark}
    Comme \(\bb P(\Omega)=1\), une mesure de probabilité est une mesure
    dans \(\ff{0,1}\). Un événement \(A\) est dit \defemph{presque sûr}
    si \(\bb P(A) = 1\).
\end{remark}

\begin{exs}\,
    \begin{enumerate}
        \item Soit \((\Omega, \scr F)\) un espace mesurable et
        \(\omega\) un élément fixé dans \(\Omega\). La mesure
        (ou masse) de Dirac en \(\omega\) est la mesure définie
        pour tout \(A\in\scr F\) par
        \begin{equation*}
            \delta_\omega(A) = \begin{cases}
                1 & \text{si } \omega\in A\\
                0 & \text{sinon}
            \end{cases}= \one_{A}(\omega)
        \end{equation*}
        On vérifie facilement que c'est bien une probabilité.

        \item Sur le segment \(\ff{0,1}\) muni de sa tribu 
        borélienne, la mesure de Lebesgue est une probabilité.

        \item Si \((\Omega,\scr F,\mu)\) est un espace mesuré avec
        \(0<\mu(\Omega)<+\infty\), alors on obtient une probabilité
        en considérant la mesure
        \begin{equation*}
            \bb P = \frac{\mu(\cdot)}{\mu(\Omega)}
        \end{equation*}
    \end{enumerate}
\end{exs}

\begin{interp}
    Un espace probabilisé est donc un cas particulier d'espace mesuré
    pour lequel la masse totale de la mesure est égale à 1. En fait,
    le point de vue diffère de la théorie de l'intégration: dans
    le cadre de la théorie des probabilités, on cherche à fournir
    un modèle mathématique pour une ``expérience aléatoire''.

    \begin{itemize}
        \item L'ensemble \(\Omega\) est appelé \defemph{univers}:
        il représente l'ensemble de toutes les éventualiés possibles,
        toutes les déterminations du hasard dans l'expérience considérée.
        Les éléments \(\omega\) de \(\Omega\), parfois appelés
        \defemph{événements élémentaires}, correspondent donc aux issues
        possibles de l'expérience aléatoire.

        \item La tribu \(\scr F\) correspond à l'ensemble des
        \defemph{événements}:  ce sont les parties de \(\Omega\) dont
        on peut évaluer la probabilité. Il faut voir un événement
        \(A\) de \(\scr F\) comme un sous-ensemble de \(\Omega\) 
        contenant toutes les éventualités \(\omega\) pour
        lesquelles une certaine propriété est vérifiée.

        \item On associe à chaque événement \(A\in\scr F\) un réel
        \(\bb P(A) \in \ff{0,1}\) qui donne la plausibilité que
        le résultat de l'expérience soit dans \(A\).
    \end{itemize}
\end{interp}

\subsection{Exemples d'espaces probabilisés}\label{subsubsec:1-2}
Suivent quelques exemples classiques d'espaces probabilisés.

\begin{exs}[]
    cours a completer
\end{exs}


% ------------------------------------------------------------------------------------------
\section{Variables aléatoires}\label{subsec:2}

\subsection{Loi d'une variable aléatoire}\label{subsubsec:2-1}

\begin{definition}
    Soit \((\Omega, \scr F, \bb P)\) un espace probabilisé et \((E, \scr E)\) un espace mesurable. 
    Une \defemph{variable aléatoire} est une application
    \begin{equation*}
        X\colon \Omega \to E
    \end{equation*}
    mesurable. C'est-à-dire 
    \begin{equation*}
        \forall A\in\scr E, X^{-1}(A) = \{\omega\in\Omega\mid X(\omega)\in A\}\in\scr F
    \end{equation*}
    Si \(E = \R\) et \(\scr E = \scr B(\R)\), on parle de \defemph{variable aléatoire réelle}.

    Si \(E = \R^d\) et \(\scr E = \scr B(\R^d)\), on parle de \defemph{variable aléatoire vectorielle}.
\end{definition}

\begin{exs}\,\\
    \(\triangleright\) Lancer de deux dés.

    On considère l'expérience aléatoire qui consiste à lancer deux dés équilibrés. Alors
    \begin{equation*}
        \Omega = {\{1,\dots,6\}}^2,\quad \scr F = \scr P(\Omega).
    \end{equation*}
    On s'intéresse à la somme des résultats obtenus et on définit
    \begin{equation*}
        \begin{aligned}
            X\colon \Omega&\to \{2,\dots,12\}\\
            (i,j) &\mapsto i+j
        \end{aligned}
    \end{equation*}
    On munit l'ensemble d'arrivée de la tribu pleine.

    \(X\) est une variable aléatoire car l'espace de départ est muni de la tribu pleine.

    \(\triangleright\) Infinité de lancers d'un dé.

    On considère l'expérience aléatoire qui consiste à lancer un dé équilibré une infinité de fois. Alors
    \begin{equation*}
        \Omega = {\{1,\dots,6\}}^{\N^\ast} = \{\omega = {(\omega_n)}_{n\in\N^\ast}\mid \omega_n\in\{1,\dots,6\}\}
    \end{equation*}

    On considère la tribu \(\scr F\) la plus petite tribu contenant les \(A_{x_1,\dots,x_k}\). On s'intéresse
    au nombre de lancers jusqu'à l'apparition du premier 6. On définit
    \begin{equation*}
        \begin{aligned}
            Y\colon \Omega&\to \N^\ast\cup\{+\infty\}\\
            \omega ={{(\omega_n)}_{n\in\N^\ast}}&\mapsto \inf\{n\in\N^\ast\mid \omega_n = 6\}
        \end{aligned}
    \end{equation*}
    avec la convention \(\inf\emptyset = +\infty\). On munit l'ensemble d'arrivée de la tribu pleine.

    Pour \(k\geq 1\), on a
    \begin{equation*}
        \begin{aligned}
            Y^{-1}(\{k\}) 
            &= \{\omega={(\omega_n)}_{n\in\N^\ast}\mid \omega_1\ne 6,\dots,\omega_{k-1}\ne 6,\omega_k = 6\}\\
            &= \bigcup_{x_1,\dots,x_{k-1}\in\{1,\dots,5\}}A_{x_1,\dots,x_{k-1},6}\in\scr F
        \end{aligned}
    \end{equation*}

    Par ailleurs,
    \begin{equation*}
        \begin{aligned}
            Y^{-1}(\{+\infty\})
            &= \{\omega={(\omega_n)}_{n\in\N^\ast}\mid \forall n\in\N^\ast, \omega_n\ne 6\}\\
            &= \bigcap_{k=1}^{+\infty}\bigcup_{x_1,\dots,x_{k}\in\{1,\dots,5\}}A_{x_1,\dots,x_{k}}\in\scr F
        \end{aligned}
    \end{equation*}

    Comme \(\N\cup\{+\infty\}\) est dénombrable, on en déduit que \(Y\) est une variable aléatoire.

    \(\triangleright\) Bouteille à la mer.

    On considère l'expérience aléatoire qui consiste à observer la position d'une bouteille à la mer. Alors
    \begin{equation*}
        \Omega = \scr C^0(\ff{0,1},\R^2)
    \end{equation*}
    On considère la tribu \(\scr F\) la plus petite tribu rendant mesurables les applications coordonnées
    \begin{equation*}
        \begin{aligned}
            f_t\colon \Omega&\to \R^2\\
            \omega &\mapsto \omega(t)
        \end{aligned}
    \end{equation*}
    On s'intéresse à la position de la bouteille au temps \(t=1\). On définit
    \begin{equation*}
        \begin{aligned}
            Z\colon \Omega&\to \R^2\\
            \omega&\mapsto \omega(1)
        \end{aligned}
    \end{equation*}

    Alors, par construction de la tribu \(\scr F\), on a que \(Z\) est une variable aléatoire.
\end{exs}

\begin{definition}
    Soit \(X\) une variable aléatoire de \((\Omega, \scr F, \bb P)\) dans \((E, \scr E)\). La \defemph{loi} de \(X\) est la mesure
    image de \(X\) par \(\bb P\), définie par
    \begin{equation*}
        \forall A\in\scr E, \bb P_X(A) = \bb P(X^{-1}(A)) = \bb P(X\in A)
    \end{equation*}
\end{definition}

\begin{exs}[]\,\\
    \(\triangleright\) Infinité de lancers d'un dé.

    On considère
    \begin{equation*}
        \begin{aligned}
            Y\colon \Omega={\{1,\dots,6\}}^{\N^\ast}&\to \N^\ast\cup\{+\infty\}\\
            \omega={{(\omega_n)}_{n\in\N^\ast}}&\mapsto \inf\{n\in\N^\ast\mid \omega_n = 6\}
        \end{aligned}
    \end{equation*}
    La loi \(\bb P_Y\) de \(Y\) est une mesure de probabilité sur \(\N^\ast\cup\{+\infty\}\).

    Soit \(k\in\N^\ast\). On a
    \begin{equation*}
        \begin{aligned}
            \bb P_Y(\{k\}) 
            &= \bb P(Y^{-1}(\{k\}))\\
            &= \bb P(Y=k)\\
            &= \bb P\left(\bigcup_{x_1,\dots,x_{k-1}\in\{1,\dots,5\}}A_{x_1,\dots,x_{k-1},6}\right)\\
            &= \sum_{x_1,\dots,x_{k-1}} \underbrace{\bb P(A_{x_1,\dots,x_{k-1},6})}_{=\frac{1}{6^k}}\\
            &= \frac{5^{k-1}}{6^k}
            &= {\left(\frac{5}{6}\right)}^{k-1}\frac{1}{6}
        \end{aligned}
    \end{equation*}

    Par ailleurs, on a vu à la fin de la section précédente que
    la probabilité de ne jamais obtenir de 6 est nulle:
    \begin{equation*}
        \bb P_Y(\{+\infty\}) = \bb P(Y^{-1}(\{+\infty\})) = \bb P(Y=+\infty) = 0
    \end{equation*}
    On en déduit que la loi de \(Y\) est 
    \begin{equation*}
        \sum_{k=1}^{+\infty} {\left(\frac{5}{6}\right)}^{k-1}\frac{1}{6}\delta_k
    \end{equation*}
    Cette loi est appelée \defemph{loi géométrique} de paramètre \(\frac{5}{6}\).
\end{exs}

\begin{definition}[Variable aléatoire discrète]
    Une variable aléatoire \(X\) est dite \defemph{discrète} si \(X\) est à valeurs dans un ensemble \(E\) au plus dénombrable.
    On prend alors \(\scr E = \scr P(E)\) et si \(A\in\scr E\), on a
    \begin{equation*}
        \bb P_X(A) = \bb P(X\in A) = \bb P(X\in\cup_{x\in A}\{x\}) = \sum_{x\in A}\bb P(X=x)
    \end{equation*}

    La loi \(\bb P_X\) de \(X\) est alors entièrement déterminée par les quantités \(p_x = \bb P(X=x)\) pour tout \(x\in E\):
    \begin{equation*}
        \bb P_X(A) = \sum_{x\in E}p_x\delta_x
    \end{equation*}
\end{definition}

\begin{definition}[Variable aléatoire à densité]
    Une variable aléatoire \(X\) à valeurs dans \((\R^d, \scr B(\R^d))\) est dite \defemph{à densité} par rapport
    à la mesure de Lebesgue \(\lambda_d\) si il existe une fonction mesurable
    \begin{equation*}
        f\colon \R^d\to \fo{0,+\infty}
    \end{equation*}
    telle que \(\bb P_X = f\lambda_d\):
    \begin{equation*}
        \forall A\in\scr B(\R^d), \bb P_X(A) = \int_A f(x)\der\lambda_d(x)
    \end{equation*}
    Il faut que \(f\) vérifie
    \begin{equation*}
        \int_{\R^d}f(x)\der\lambda_d(x) = 1
    \end{equation*}
    Par exemple, si \(d=1\), on a
    \begin{equation*}
        \bb P_X\left(\ff{a,b}\right) = \int_a^b f(x)\der\lambda_1(x)
    \end{equation*}
    On notera souvent \(f_X = f\) et on appelle cette fonction la \defemph{densité} de \(X\).
\end{definition}

\subsection{Lois usuelles}\label{subsubsec:2-2}

% subsubsubsection ?

\(\triangleright\) Lois discrètes:

Loi uniforme sur un ensemble fini \(\{x_1,\dots,x_n\}\).

Soit \(E = \{x_1,\dots,x_n\}\) un ensemble fini. 

Une variable aléatoire \(X\) suit une loi uniforme sur \(E\), notée \(X\sim\mathcal U(E)\), si sa loi est
\begin{equation*}
    \bb P_X = \frac{1}{n}\sum_{i=1}^n\delta_{x_i}
\end{equation*}
c'est-à-dire
\begin{equation*}
    \bb P_X(A) = \bb P(X\in A) = \frac{\text{card}(A)}{n}
\end{equation*}


\(\triangleright\) Loi de Bernoulli.

Une variable aléatoire \(X\) suit une loi de Bernoulli de paramètre \(p\in\ff{0,1}\), notée \(X\sim\mathcal B(p)\), si sa loi est
\begin{equation*}
    \bb P_X = p\delta_1 + (1-p)\delta_0
\end{equation*}
c'est-à-dire
\begin{equation*}
    \bb P(X=1) = p,\quad \bb P(X=0) = 1-p
\end{equation*}


\(\triangleright\) Loi binomiale.

Une variable aléatoire \(X\) suit une loi binomiale de paramètres \(n\in\N^\ast\) et \(p\in\ff{0,1}\), notée \(X\sim\mathcal B(n,p)\), si sa loi est
\begin{equation*}
    \bb P_X = \sum_{k=0}^n\binom{n}{k}p^k{(1-p)}^{n-k}\delta_k
\end{equation*}
cela correspond au nombre de succès dans \(n\) répétitions d'une expérience de Bernoulli de paramètre \(p\) (de manière indépendante).


\(\triangleright\) Loi géométrique.

Une variable aléatoire \(X\) suit une loi géométrique de paramètre \(p\in\of{0,1}\), notée \(X\sim\mathcal G(p)\), si sa loi est
\begin{equation*}
    \bb P_X = \sum_{k=1}^{+\infty}p{(1-p)}^{k-1}\delta_k
\end{equation*}
c'est-à-dire
\begin{equation*}
    \bb P(X=k) = p{(1-p)}^{k-1}
\end{equation*}
cela correspond au nombre de répétitions d'une expérience de Bernoulli de paramètre \(p\) avant le premier succès.


\(\triangleright\) Loi de Poisson.

Une variable aléatoire \(X\) suit une loi de Poisson de paramètre \(\theta>0\), notée \(X\sim\mathcal P(\theta)\), si sa loi est
\begin{equation*}
    \bb P_X = \sum_{k=0}^{+\infty}\frac{\theta^k}{k!}e^{-\theta}\delta_k
\end{equation*}
c'est-à-dire
\begin{equation*}
    \bb P(X=k) = \frac{\theta^k}{k!}e^{-\theta}
\end{equation*}
cela correspond au nombre d'événements rares dans un intervalle de temps donné.

% subsubsubsection 2? 

\(\triangleright\) Lois à densité sur \(\R^d\):


Loi uniforme sur un ensemble \(A\) de \(\R^d\).

Soit \(A\in\scr B(\R^d)\), telle que \(0<\lambda_d(A)<+\infty\). 
Une variable aléatoire \(X\) suit une loi uniforme sur \(A\), notée \(X\sim\mathcal U(A)\), si sa loi est
\begin{equation*}
    \bb P_X = \frac{1}{\lambda_d(A)}\one_A
\end{equation*}
c'est-à-dire \(\bb P_X\) admet la densité constante \(\frac{1}{\lambda_d(A)}\one_A\). Autrement dit,
si \(B\in\scr B(\R^d)\), on a
\begin{equation*}
    \bb P_X(B) = \int_B \frac{1}{\lambda_d(A)}\one_A(x)\der\lambda_d(x) = \frac{\lambda_d(A\cap B)}{\lambda_d(A)}
\end{equation*}
dans le cas \(d=1\) et \(A = \ff{a,b}\), la densité est \(f(x) = \frac{\one_{\ff{a,b}}(x)}{b-a}\).


\(\triangleright\) Loi exponentielle.

Une variable aléatoire \(X\) suit une loi exponentielle de paramètre \(\theta>0\), notée \(X\sim\mathcal E(\theta)\), si sa loi est
\begin{equation*}
    \bb P_X = \theta e^{-\theta x}\lambda_1\one_{\R^+}
\end{equation*}
c'est-à-dire \(\bb P_X\) admet la densité \(f_X(x)\theta e^{-\theta x}\one_{\R^+}\) par rapport à la mesure de Lebesgue \(\lambda_1\). Autrement dit,
si \(A\in\scr B(\R)\), on a
\begin{equation*}
    \bb P_X(A) = \int_A \theta e^{-\theta x}\one_{\R_+}(x)\der\lambda_1(x)
\end{equation*}
dans le cas \(d=1\). Cette loi vérifie la propriété de l'absence de mémoire, c'est-à-dire
\begin{equation*}
    \forall s,t\geq 0, \bb P(X>s+t\mid X>s) = \bb P(X>t)
\end{equation*}


\(\triangleright\) Loi normale ou gaussienne.

Une variable aléatoire \(X\) suit une loi normale de paramètres \(\mu\in\R\) et \(\sigma>0\), notée \(X\sim\mathcal N(\mu,\sigma^2)\), si sa loi est
\begin{equation*}
    \bb P_X = f_X\lambda_1
\end{equation*}
où \(f_X\) est la densité de la loi normale, donnée par
\begin{equation*}
    f_X(x) = \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{{(x-\mu)}^2}{2\sigma^2}}
\end{equation*}
Autrement dit, si \(A\in\scr B(\R)\), on a
\begin{equation*}
    \bb P_X(A) = \int_A \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{{(x-\mu)}^2}{2\sigma^2}}\der\lambda_1(x)
\end{equation*}
remarque, la loi \(\cal N(0,1)\), c'est-à-dire avec la densité
\begin{equation*}
    f_X(x) = \frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}
\end{equation*}
est appelée loi normale standard.


\section{Moments d'une variable aléatoire} %2.3

On considère dans la suite \(\left(\Omega, \scr F, \bb P\right)\) un
espace probabilisé

\subsection{Espérance} % 2.3.1

\begin{definition}
    Soit \(X\colon\Omega\to\bb R\) une variable aléatoire réelle.
    On appelle \defemph{espérance} de \( X\) la quantité
    \begin{equation*}
        \bb E\ff X = \int_{\Omega} X(\omega) \der\bb P(\omega)
    \end{equation*}
    qui est bien définie si \(X\) est positive ou si 
    \(X\in\scr L^1\left(\Omega, \scr F, \bb P\right)\).

    On définit de même l'espérance d'une variable aléatoire
    \(X\colon\Omega\to\bb C\). Sk \(X=\left(X_1,\ldots,X_d\right)\)
    est un vecteur aléatoire, alors on pose
    \begin{equation*}
        \bb E\ff X = \left(\bb E\ff{X_1},\ldots,\bb E\ff{X_d}\right)
    \end{equation*}
    si \(\bb E\ff{X_i}\) existe pour tout \(i\in\{1,\ldots,d\}\).
\end{definition}

\begin{remark}\,
    \begin{enumerate}
        \item On interprète \(\bb E\ff X\) comme la valeur moyenne de \(X\).

        \item Si \(\bb E\ff X = 0\), on dit que \(X\) est \defemph{centrée}.

        \item Si \(X = \one_A\), alors \(\bb E\ff X = \bb P(A)\).

        \item On omettra le cas où \(X\) est positive et \(\bb E\ff X = +\infty\).
    \end{enumerate}
\end{remark}

\begin{proposition}
    Soient \(X\) et \(Y\) deux variables aléatoires admettant une espérance
    et \(a,b\in\bb R\). Alors
    \begin{equation*}
        \bb E\ff{aX + bY} = a\bb E\ff X + b\bb E\ff Y
    \end{equation*}

    De plus, si \(X>0\), alors \(\bb E\ff X\geq 0\) avec
    \(\bb E\ff X = 0\) si et seulement si \(X=0\)-\(\bb P\)-p.p.
\end{proposition}

\begin{proposition}[Formule de transfert]
    Soit \(X\colon \Omega\to E\) une variable aléatoire à valeurs
    dans un espace mesurable\(\left(E, \scr E\right)\). Soit
    \(h\colon E\to\bb R\) une fonction mesurable positive.

    Alors, \(h\circ X\) est une variable aléatoire et
    \begin{equation*}
        \begin{aligned}
            \bb E\ff{h(X)} 
            &= \int_{\Omega} h(X(\omega))\der\bb P(\omega)\\
            &=\int_{E} h(x)\der\bb P_X(x)
        \end{aligned}
    \end{equation*}

    Si \(h\colon E\to\bb R\) et mesurable (pas forcément positive),
    alors \(h\in\scr L^1\left(E, \scr E, \bb P_X\right)\) si et seulement
    si \(h\circ X\in\scr L^1\left(\Omega, \scr F, \bb P\right)\)
    et l'égalité précédente reste vraie.
\end{proposition}

\begin{proof}
    Vue en théorie de la mesure.

    On vérifie l'égalité:
    \begin{itemize}
        \item pour les fonctions indicatrices,
        \item pour les fonctions étagées,
        \item pour les fonctions positives,
        \item pour les fonctions intégrables
    \end{itemize}
\end{proof}

\begin{remark}
    En particulier, si \(E = \bb R\) et \(h=\id_{\bb R}\), on 
    obtient
    \begin{equation*}
        \bb E\ff X = \int_{\bb R} x\der\bb P_X(x)
    \end{equation*}
    à condition que cette quantité existe.
\end{remark}

\begin{exs}
    Loi de Bernoulli
    \begin{equation*}
        \bb P_X = (1-p)\delta_0 + p\delta_1\\
    \end{equation*}
    \begin{equation*}
        \begin{aligned}
            \bb E\ff X 
            &= \int_{\bb R} x\der\bb P_X(x) \\
            &= \int_{\bb R} x \der\left((1-p)\delta_0 + p\delta_1\right)(x)\\
            &=(1-p)\underbrace{\int_{\bb R} x \der\delta_0(x)}_{=0} + p \underbrace{\int_{\bb R} x\der\delta_1(x)}_{=1}\\
            &= p
        \end{aligned}
    \end{equation*}

    Si \(X\) suit une loi discrète
    \begin{equation*}
        \bb P_X = \sum_{k=1}^{\infty}p_k\delta_{i_k}
    \end{equation*}
    alors son espérance vaut
    \begin{equation*}
        \begin{aligned}
            \bb E\ff X
            &= \int_{\R} x\der\bb P_X\\
            &=\sum_{k=1}^\infty p_k \underbrace{\int_{\R} x\der\delta_{x_k}}_{=x_k}\\
            &=\sum_{k=1}^{\infty} p_k x_k
        \end{aligned}
    \end{equation*}
\end{exs}

\begin{proposition}
    Soit \(X\colon \Omega\to E\) une variable aléatoire.
    La loi de \(X\) est caractérisée par les quantités
    \(\bb E\ff{h(X)}\) où \(h\colon E\to\bb R\) décrit l'ensemble
    des fonctions mesurables bornées. 

    C'est-à-dire, si \(X\) et \(X'\) sont deux variables aléatoires
    vérifiant
    \begin{equation*}
        \bb E\ff{h(X)} = \bb E\ff{h(X')}
    \end{equation*}
    pour toute fonction \(h\) mesurable bornée, alors \(X\) et \(X'\)
    ont la même loi.
\end{proposition}

\begin{proof}
    Soient \(X\) et \(X'\) telles que \(\bb E\ff{h(X)} = \bb E\ff{h(X')}\)
    pour toute fonction \(h\) mesurable bornée.

    Soit \(A\in\scr E\). On pose \(h = \one_A\) et alors
    \begin{equation*}
        \bb P(X\in A) = \bb E\ff{\one_A(X)} = \bb E\ff{h(X)} = \bb E\ff{h(X')} = \bb E\ff{\one_A(X')} = \bb P(X'\in A)
    \end{equation*}
    Donc \(X\) et \(X'\) ont la même loi.
\end{proof}

\begin{exs}
    On considère une variable aléatoire \(X\) de loi uniforme sur \(\oo{0,1}\)
    et on pose \(Y = -\ln(X)\). Déterminons la loi de \(Y\).

    Soit \(h\) une fonction mesurable bornée. Alors
    \begin{equation*}
        \begin{aligned}
            \bb E\ff{h(Y)} 
            &= \bb E\ff{h(-\ln(X))}\\
            &= \int_{\R} h(-\ln(x))\der\bb P_X(x)\\
            &= \int_{\R} h(-\ln(x)) \underbrace{\one_{\oo{0,1}}(x)\der\lambda_1(x)}_{=\bb P_X}\\
            &= \int_{\R} h(y) \underbrace{\one_{\oo{0,\infty}}(y) e^{-y}\der\lambda_1(y)}_{=\bb P_X}\qquad\text{ avec }y=-\ln(x)
        \end{aligned}
    \end{equation*}
    D'après la proposition précédente, la loi de \(Y\) est
    \begin{equation*}
        \one_{\oo{0,\infty}}(y)e^{-y}\lambda_1(y)
    \end{equation*}
    c'est-à-dire que \(Y\) suit une loi exponentielle de paramètre 1.
\end{exs}

\subsection{Moments d'ordre \(p\)} % 2.3.2

Pour \(p\in\fo{1,\infty}\), on définit l'espace \(\scr L^p(\Omega, \scr F, \bb P)\)
comment l'ensemble des variables aléatoires vérifiant
\begin{equation*}
    \nn{X}_p = {\left(\int_{\Omega}\n{X(\omega)}^p\der\bb P(\omega)\right)}^{\frac1p}<\infty
\end{equation*}

On a bien que \(\nn\cdot_p\) est une norme qui rend \(\scr L^p(\Omega, \scr F, \bb P)\) complet
(toute suite de Cauchy converge).

Dans le cas \(p=\infty\), on pose
\begin{equation*}
    \nn X_\infty = \sup_{\omega\in\Omega}\n{X(\omega)}=\lim_{p\to\infty}\nn X_p
\end{equation*}
Donc \(\scr L^\infty (\Omega,\scr F,\bb P)\) est l'ensemble des variables aléatoires bornées.

\begin{definition}
    Soit \(p\in\fo{1,\infty}\) et \(X\) une variable aléatoire dans
    \(\scr L^p(\Omega, \scr F, \bb P)\). Le \defemph{moment d'ordre \(p\)} de
    \(X\) est
    \begin{equation*}
        \bb E\ff{X^p} = \int_{\Omega} {X(\omega)}^p\der\bb P(\omega) = \int_{\bb R}x^p\der\bb P_X(x)
    \end{equation*}
\end{definition}

\begin{remark}\,
    \begin{enumerate}
        \item Le moment d'ordre 1 correspond à l'espérance.

        \item Si \(p\leq q\) alors \(\scr L^q(\Omega, \scr F, \bb P)\subset \scr L^p(\Omega, \scr F, \bb P)\)

        En particulier, si \(X\) admet un moment d'ordre \(q\) alors \(X\) admet un moment
        d'ordre \(p\) pour tout \(p\leq q\)
    \end{enumerate}
\end{remark}

\begin{proposition}[Inégalité de Markov]
    Soit \(X\) une variable aléatoire réelle positive et
    \(p\in\fo{1,\infty}\). Alors, pour tout \(t> 0\), on a
    \begin{equation*}
        \bb P(X\geq t) \leq \frac{\bb E\ff{X^p}}{t^p}
    \end{equation*}

    Cette inégalité permet de contrôler le comportement à l'infini
    de \(X\).
\end{proposition}

\begin{proof}
    On part de l'inégalité
    \begin{equation*}
        t^p\one_{\{X\geq t\}}\leq X^p
    \end{equation*}
    On applique l'espérance
    \begin{equation*}
        \begin{aligned}
            t^p\bb E\ff{\one_{\{X\geq t\}}} &\leq \bb E\ff{X^p}\\
            \bb P(X\geq t)&\leq \frac{\bb E\ff{X^p}}{t^p}
        \end{aligned}
    \end{equation*}
\end{proof}

% paragraphe non numéroté

Le cas \(\scr L^2(\Omega, \scr F, \bb P)\):

On rappelle que \(\scr L^2(\Omega, \scr F, \bb P)\) est muni d'un
produit scalaire
\begin{equation*}
    \langle X,Y\rangle = \bb E\ff{XY} = \int_{\Omega} X(\omega)Y(\omega)\der\bb P(\omega)
\end{equation*}
La norme associée est
\begin{equation*}
    \nn X_2 = \sqrt{\langle X, X\rangle} = \sqrt{\int_{\Omega}{X(\omega)}^2\der\bb P(\omega)}
\end{equation*}

\begin{definition}
    La \defemph{variance} d'une variable aléatoire réelle \(X\) est le 
    moment d'ordre 2 de \(X-\bb E\ff X\), soit
    \begin{equation*}
        \var(X) = \nn{X-\bb E\ff X}_2^2 = \int_{\Omega}{\left(X(\omega) -\bb E\ff X\right)}^2\der\bb P(\omega),
    \end{equation*}
    qui est bien définie si \(X\in\scr L^2(\Omega, \scr F, \bb P)\).

    On définit \defemph{l'écart-type} par
    \begin{equation*}
        \sigma(X) = \sqrt[\var(X)] = \nn{X-\bb E\ff X}_2
    \end{equation*}
\end{definition}

\begin{remark}\,
    \begin{enumerate}
        \item En développant le carré dans la définition de la variance,
        on obtient
        \begin{equation*}
            \var(X) = \bb E\ff{X^2} - {\bb E\ff X}^2
        \end{equation*}

        \item On a \(\var(X) = 0\) si et seulement si \(X\)
        est constante.
    \end{enumerate}
\end{remark}

\begin{proposition}[Inégalité de Bienaymé-Tchebychev]
    Soit \(X\) une variable aléatoire dans \(\scr L^2(\Omega, \scr F, \bb P)\).
    Alors, pour tout \(t>0\), on a
    \begin{equation*}
        \bb P\left(\n{X-\bb E\ff X}_2\geq t\right)\leq \frac{\var(X)}{t^2}
    \end{equation*}
\end{proposition}

\begin{definition}
    Soient \(X\) et \(Y\) deux variables aléatoires dans \(\scr L^2(\Omega, \scr F, \bb P)\).
    On définit la \defemph{covariance} de \(X\) et \(Y\) par
    \begin{equation*}
        \text{COV}(X,Y) = \bb E\ff{(X-\bb E\ff X)(Y-\bb E\ff Y)} = \langle X-\bb E\ff X, Y-\bb E\ff Y\rangle
    \end{equation*}
    où on rappelle que
    \begin{equation*}
        \langle U, V\rangle = \bb E\ff{UV} = \int_{\Omega} U(\omega)V(\omega)\der\bb P(\omega)
    \end{equation*}

    Par les propriétés du produit scalaire dans \(\scr L^2(\Omega, \scr F, \bb P)\), on en
    déduit que la covariance est symétrique, bilinéaire et positive:
    \begin{equation*}
        \text{COV}(X,X) = \var(X) \geq 0
    \end{equation*}

    Par ailleurs, on a aussi la relation de Pythagore:
    \begin{equation*}
        \var(X+Y) = \var(X) + \var(Y) + 2\text{COV}(X,Y)
    \end{equation*}
\end{definition}

\subsection{Moments de lois usuelles}

Sous forme de tableau:

\begin{equation*}
    \begin{array}{|c|c|c|}
        \hline
        \text{Loi} & \text{Espérance} & \text{Variance}\\
        \hline
        \mathcal U(\{1,\ldots,n\}) & \frac{n+1}2 & \frac{n^2-1}{12}\\
        \hline
        \mathcal B(p) & p & p(1-p)\\
        \hline
        \mathcal B(n,p) & np & np(1-p)\\
        \hline
        \mathcal G(p) & \frac{1}{p} & \frac{1-p}{p^2}\\
        \hline
        \mathcal P(\theta) & \theta & \theta\\
        \hline
        \mathcal U(\ff{a,b}) & \frac{a+b}{2} & \frac{{(b-a)}^2}{12}\\
        \hline
        \mathcal E(\theta) & \frac{1}{\theta} & \frac{1}{\theta^2}\\
        \hline
        \mathcal N(\mu,\sigma^2) & \mu & \sigma^2\\
        \hline
    \end{array}
\end{equation*}

\section{Fonctions associées à une variable aléatoire}

\subsection{Fonction de répartition}

\begin{definition}
    Soit \(X\) une variable aléatoire réelle. La \defemph{fonction de répartition} de \(X\)
    est la fonction
    \begin{equation*}
        F_X\colon \bb R\to\ff{0,1},\quad t\mapsto \bb P(X\leq t)
    \end{equation*}
\end{definition}

\begin{example}
    Si \(X\) est une variable réelle de densité \(f_X\) par rapport à la mesure de Lebesgue
    \(\left(\bb P_X = f_X\lambda_1\right)\), alors
    \begin{equation*}
        \bb P_X(A) = \int_A f_X(t)\der\lambda_1(t)
    \end{equation*}
    Donc, la fonction de répartition de \(X\) est donnée par
    \begin{equation*}
        F_X(t) = \bb P_X\left(\ff{-\infty,t}\right) = \int_{-\infty}^t f_X(u)\der\lambda_1(u)
    \end{equation*}
    Par exemple, si \(X\sim\mathcal E(\theta)\), c'est-à-dire
    \begin{equation*}
        f_X(t) = \theta e^{-\theta t}\one_{\R_+}(t)
    \end{equation*}
    alors
    \begin{equation*}
        \begin{aligned}
            F_X(t)
            &= \int_{-\infty}^t \theta e^{-\theta u}\one_{\R_+}(u)\der\lambda_1(u)\\
            &= \begin{cases}
                0 & \text{si } t<0\\
                \ff{-e^{-\theta u}}_0^t & \text{si } t\geq 0
            \end{cases}\\
            &= \left(1-e^{-\theta t}\right)\one_{\R_+}(t)
        \end{aligned}
    \end{equation*}
    De manière générale, l'égalité \(F_X(t) = \int_{-\infty}^t f_X(u)\der\lambda_1(u)\) assure que
    \(F_X\) est dérivable \(\lambda_1\)-p.p, avec \(F_X'(t) = f_X(t)\) pour \(\lambda_1\)-presque tout \(t\in\bb R\).
\end{example}

\begin{example}
    On considère \(X\sim\mathcal B(p)\) et \(\bb P_X = (1-p)\delta_0 + p\delta_1\).
    Alors, la fonction de répartition de \(X\) est donnée par
    \begin{equation*}
        \begin{aligned}
            F_X(t) 
            &= \bb P_X\left(\ff{-\infty,t}\right)\\
            &= (1-p)\delta_0\left(\ff{-\infty,t}\right) + p\delta_1\left(\ff{-\infty,t}\right)\\
            &= \begin{cases}
                0 & \text{si } t<0\\
                1-p & \text{si } 0\leq t<1\\
                1 & \text{si } t\geq 1
            \end{cases}
        \end{aligned}
    \end{equation*}
    Plus généralement, si \(X\) est une variable aléatoire discrète de loi \(\bb P_X = \sum_{k\in E}p_k\delta_{x_k}\), avec
    les \(x_k\) ordonnés, alors
    \begin{equation*}
        F_X(t) = \sum_{k=0}^{\infty} p_k\delta_{x_k}\left(\ff{-\infty,t}\right) = \sum_{k=0}^{\infty} p_k\one_{\fo{x_k,+\infty}}(t)
    \end{equation*}
\end{example}

\begin{proposition}
    Soit \(X\) une variable aléatoire réelle de fonction de répartition \(F_X\). Alors
    \begin{enumerate}
        \item \(F_X\) est croissante, continue à droite et admet des limites à gauche (càdlàg)
        \item Les limites de \(F_X\) en \(-\infty\) et \(+\infty\) sont
        \begin{equation*}
            \lim_{t\to\infty} F_X(t) = 1,\quad \lim_{t\to-\infty} F_X(t) = 0
        \end{equation*}
        \item En posant
        \begin{equation*}
            F_X(t-) = \lim_{\substack{\varepsilon\to 0\\ \varepsilon>0} } F_X(t-\varepsilon)
        \end{equation*}
        On a
        \begin{equation*}
            F_X(t-) = \bb P(X<t) = \bb P(X\leq t)
        \end{equation*}
        et donc
        \begin{equation*}
            \bb P(X=t) = F_X(t) - F_X(t-)
        \end{equation*}
    \end{enumerate}
\end{proposition}

\begin{proof}
    Admise (ou a faire en exercice)
\end{proof}

\begin{proposition}
    La fonction de répartition d'une variable aléatoire \(X\) caractérise sa loi. C'est à dire que deux variables
    aléatoires ayant la même fonction de répartition ont la même loi.
\end{proposition}

\begin{proof}
    Si \(F_X = F_Y\) alors
    les mesures de probabilités \(\bb P_X\) et \(\bb P_Y\) associées à \(X\) et \(Y\) coïncident sur les
    ensembles de la forme \(\ff{-\infty,t}\). Ces ensembles engendrent la tribu borélienne de \(\bb R\) et
    sont stables par intersection finie, donc le lemme de classes monotones assure que \(\bb P_X = \bb P_Y\).
\end{proof}

\subsection{Fonction caractéristique}

\begin{definition}
    Soit \(X\) une variable aléatoire réelle. La \defemph{fonction caractéristique} de \(X\) est la fonction
    \begin{equation*}
        \begin{aligned}
            \varphi_X\colon \bb R &\to\bb C\\
            t &\mapsto \bb E\ff{e^{itX}} = \int_{\Omega} e^{itX(\omega)}\der\bb P(\omega)
        \end{aligned}
    \end{equation*}
\end{definition}

\begin{remark}\,
    \begin{enumerate}
        \item La fonction caractéristique est bien définie car
        \begin{equation*}
            \int_{\Omega}\n{e^{itX(\omega)}}\der\bb P(\omega) = \int_{\Omega} \der\bb P(\omega) = 1
        \end{equation*}

        \item La fonction caractéristique correspond à un signe près à la transformée de Fourier de la
        variable aléatoire \(X\).
    \end{enumerate}
\end{remark}

\begin{example}\,
    \begin{itemize}
        \item Soit \(X\sim\mathcal B(p)\). Alors
        \begin{equation*}
            \varphi_X(t) = \bb E\ff{e^{itX}} = (1-p)e^{it0} + pe^{it1} = 1-p+pe^{it}
        \end{equation*}

        \item Soit \(X\) une variable aléatoire discrète de loi \(\bb P_X = \sum_{k\in E}p_k\delta_{x_k}\).
        Alors
        \begin{equation*}
            \varphi_X(t) = \bb E\ff{e^{itX}} = \sum_{k\in E}p_k e^{itx_k}
        \end{equation*}

        \item Soit \(X\sim\mathcal U(\ff{a,b})\). Alors
        \begin{equation*}
            \begin{aligned}
                \varphi_X(t) 
                &= \bb E\ff{e^{itX}}\\
                &= \int_{\bb R} e^{itx}\frac{1}{b-a}\one_{\ff{a,b}}(x)\der\lambda_1(x)\\
                &= \ff{\frac{e^{itx}}{it}}_a^b\\
                &= \frac{e^{itb}-e^{ita}}{it(b-a)}\quad \text{si } t\neq 0
            \end{aligned}
        \end{equation*}
        et pour \(t=0\), on a 
        \begin{equation*}
            \varphi_X(0) = \bb E\ff{e^{i0X}} = \bb E\ff{1} = 1
        \end{equation*}

        \item Soit \(X\sim\mathcal N(0,1)\). Alors
        \begin{equation*}
            \varphi_X(t) = \bb E\ff{e^{itX}} = \int_{\bb R} e^{itx}\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}\der\lambda_1(x) = e^{-\frac{t^2}{2}}
        \end{equation*}
        cf. TD4 pour le calcul de l'intégrale.
    \end{itemize}
\end{example}

\begin{proposition}
    Soit \(X\) une variable aléatoire réelle. Si \(X\) admet un moment d'ordre \(p\in\bb N\),
    alors la fonction caractéristique \(\varphi_X\) est de classe \(\scr C^p\) et
    \begin{equation*}
        \bb E\ff{X^p} = {\left(-i\right)}^p \varphi_X^{(p)}(0)
    \end{equation*}
\end{proposition}

\begin{proof}
    La fonction \(g:(t,\omega)\mapsto e^{itX(\omega)}\) est intégrable par rapport à \(\omega\),
    dérivable par rapport à \(t\) et vérifie
    \begin{equation*}
        \n{\frac{\partial g}{\partial t}(t,\omega)} = \n{iX(\omega)e^{itX(\omega)}}=\n{X(\omega)}
    \end{equation*}
    Donc si \(X\) admet un moment d'ordre 1, alors
    \begin{equation*}
        \n{\frac{\partial g}{\partial t}(t,\omega)} = \n{X(\omega)}
    \end{equation*}
    qji est intégrable, donc le théorème de dérivation sous le signe intégral assure que
    \begin{equation*}
        \varphi_X'(t) = \int_{\Omega} iX(\omega)e^{itX(\omega)}\der\bb P(\omega)
    \end{equation*}
    en particulier, en \(t=0\), on a
    \begin{equation*}
        \varphi_X'(0) = i\bb E\ff{X}
    \end{equation*}
    On raisonne ensuite par récurrence sur \(p\) pour les autres moments.
\end{proof}

\begin{theorem}
    La fonction caractéristique \(\varphi_X\) caractérise la loi de \(X\). C'est-à-dire que si
    \(\varphi_X = \varphi_Y\) alors \(X\) et \(Y\) ont la même loi.
\end{theorem}

\begin{proof}
    Admise, elle est basée sur l'injectivié de la transformée de Fourier de mesures.
\end{proof}

\subsection{Fonction génératrice}

On considère ici des variables aléatoires à valeurs dans \(\bb N\).

\begin{definition}
    Soit \(X\) une variable aléatoire à valeurs dans \(\bb N\). La \defemph{fonction génératrice} de \(X\)
    est la série entière
    \begin{equation*}
        G_X(z) = \bb E\ff{z^X} = \sum_{n=0}^{\infty} \bb P(X=n)z^n
    \end{equation*}
    Comme \(\sum_{n=0}^{\infty} \bb P(X=n) = 1\), on en déduit que le rayon de convergence de cette série
    entière est au moins 1, donc \(G_X\) est définie sur \(\ff{-1,1}\) et continue sur \(\ff{-1,1}\).
    Par ailleurs, \(G_X\) est de classe \(\scr C^\infty\) sur \(\oo{-1,1}\) avec
    \begin{equation*}
        \bb P(X=n) = \frac{G_X^{(n)}(0)}{n!}
    \end{equation*}

    Donc \(G_X\) caractérise la loi de \(X\).

    En dérivant \(G_X\) terme à terme, on obtient
    \begin{equation*}
        G_X'(z) = \sum_{n=1}^{\infty} n\bb P(X=n)z^{n-1} = \bb E\ff{Xz^{X-1}}
    \end{equation*}
    On prend une suite \({(z_k)}_{k\in\bb N}\) qui croit vers 1. Alors, la suite
    des fonctions \({\left(X {z_k}^{X-1}\right)}_k\) est croissante, positive et
    donc par le théorème de convergence monotone, on a
    \begin{equation*}
        \bb E\ff{\lim_{k\to\infty} X{z_k}^{X-1}} = \lim_{k\to\infty} \underbrace{\bb E\ff{X{z_k}^{X-1}}}_{G_X'(z_k)}
    \end{equation*}
    d'où
    \begin{equation*}
        \bb E\ff{X} = \lim_{\substack{z\to 1\\ z<1}} G_X'(z)
    \end{equation*}
    On peut noter \(G_X'(1-) = \lim_{\substack{z\to 1\\ z<1}} G_X'(z)\).

    Bref, si \(X\) admet un moment d'ordre 1, alors \(G_X'(1-) = \bb E\ff X\).

    Plus généralement, on peut montrer que 
    \begin{equation*}
        G_X^{(k)}(1-) = \bb E\ff{X(X-1)\ldots(X-k+1)}
    \end{equation*}
    pour tout \(k\in\bb N\). Cela permet de déterminer les moments de \(X\).
\end{definition}

\begin{example}
    \(\triangleright\) Soit \(X\sim\mathcal B(p)\). Alors
    \begin{equation*}
        G_X(z) = \bb E\ff{z^X} = (1-p)z^0 + pz^1 = 1-p+pz
    \end{equation*}
    et donc
    \begin{equation*}
        G_X'(z) = p
    \end{equation*}
    donc
    \begin{equation*}
        \bb E\ff X = G_X'(1) = p
    \end{equation*}

    \(\triangleright\) Soit \(X\sim\mathcal B(n,p)\). Alors
    \begin{equation*}
        \begin{aligned}
            G_X(z) = \bb E\ff{z^X}
            &= \sum_{k=0}^n \binom{n}{k}p^k{(1-p)}^{n-k}z^k\\
            &= {(pz + 1-p)}^n
        \end{aligned}
    \end{equation*}
    donc
    \begin{equation*}
        G_X'(z) = np{(pz + 1-p)}^{n-1}
    \end{equation*}
    et donc
    \begin{equation*}
        \bb E\ff X = G_X'(1) = np
    \end{equation*}

    \(\triangleright\) Soit \(X\sim\mathcal G(p)\). Alors
    \begin{equation*}
        \begin{aligned}
            G_X(z) = \bb E\ff{z^X}
            &= \sum_{k=1}^{\infty} p{(1-p)}^{k-1}z^k\\
            &= zp\sum_{k=1}^{\infty} {(1-p)z}^{k-1}\\
            &= \frac{zp}{1-(1-p)z}
        \end{aligned}
    \end{equation*}
    et
    \begin{equation*}
        \bb E\ff X = G_X'(1) \to \text{exercice}
    \end{equation*}

    \(\triangleright\) Soit \(X\sim\mathcal P(\theta)\). Alors
    \begin{equation*}
        \begin{aligned}
            G_X(z) = \bb E\ff{z^X}
            &= \sum_{k=0}^{\infty} e^{-\theta}\frac{\theta^k}{k!}z^k\\
            &= e^{-\theta}\sum_{k=0}^{\infty} \frac{{(\theta z)}^k}{k!}\\
            &= e^{-\theta}e^{\theta z}\\
            &= e^{\theta(z-1)}
        \end{aligned}
    \end{equation*}
    donc
    \begin{equation*}
        G_X'(z) = \theta e^{\theta(z-1)}
    \end{equation*}
    et donc
    \begin{equation*}
        \bb E\ff X = G_X'(1) = \theta
    \end{equation*}
\end{example}