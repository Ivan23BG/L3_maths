\subsection{Espaces probabilisés}\label{subsec:1}
%\addcontentsline{toc}{subsection}{\nameref{subsec:1}}


\subsubsection{Probabilité}\label{subsubsec:1-1}
\setcounter{subsection}{0}
%\addcontentsline{toc}{subsubsection}{\nameref{subsubsec:1}}
\begin{definition}
    Soit \((\Omega, \scr F)\) un espace mesurable. Une
    \defemph{mesure} sur \((\Omega, \scr F)\) est une application
    \begin{equation*}
        \begin{aligned}
            \mu\colon \scr F &\to \ff{0,+\infty}\\
            A &\mapsto \mu(A)
        \end{aligned}
    \end{equation*}
    qui vérifie les propriétés suivantes:
    \begin{enumerate}
        \item \(\mu(\emptyset) = 0\)
        \item \(\mu\) est \(\sigma\)-additive, c'est-à-dire que pour
        toute suite \({(A_n)}_{n\in\N}\) d'éléments 2 à 2
        disjoints de \(\scr F\), on a
        \begin{equation*}
            \mu\left(\bigcup_{n\in\N}A_n\right) = \sum_{n\in\N}\mu(A_n)
        \end{equation*}
    \end{enumerate}

    On dit alors que \((\Omega, \scr F,\mu)\) est un \defemph{espace
    mesuré}.

    Si de plus \(\mu(\Omega) = 1\), on dit que \((\Omega, \scr F,\mu)\)
    est un \defemph{espace probabilisé} et \(\mu\) est une \defemph{probabilité}.

    On notera alors \(\mu = \bb P\).
\end{definition}

\begin{remark}
    Comme \(\bb P(\Omega)=1\), une mesure de probabilité est une mesure
    dans \(\ff{0,1}\). Un événement \(A\) est dit \defemph{presque sûr}
    si \(\bb P(A) = 1\).
\end{remark}

\begin{exs}\,
    \begin{enumerate}
        \item Soit \((\Omega, \scr F)\) un espace mesurable et
        \(\omega\) un élément fixé dans \(\Omega\). La mesure
        (ou masse) de Dirac en \(\omega\) est la mesure définie
        pour tout \(A\in\scr F\) par
        \begin{equation*}
            \delta_\omega(A) = \begin{cases}
                1 & \text{si } \omega\in A\\
                0 & \text{sinon}
            \end{cases}= \one_{A}(\omega)
        \end{equation*}
        On vérifie facilement que c'est bien une probabilité.

        \item Sur le segment \(\ff{0,1}\) muni de sa tribu 
        borélienne, la mesure de Lebesgue est une probabilité.

        \item Si \((\Omega,\scr F,\mu)\) est un espace mesuré avec
        \(0<\mu(\Omega)<+\infty\), alors on obtient une probabilité
        en considérant la mesure
        \begin{equation*}
            \bb P = \frac{\mu(\cdot)}{\mu(\Omega)}
        \end{equation*}
    \end{enumerate}
\end{exs}

\begin{interp}
    Un espace probabilisé est donc un cas particulier d'espace mesuré
    pour lequel la masse totale de la mesure est égale à 1. En fait,
    le point de vue diffère de la théorie de l'intégration: dans
    le cadre de la théorie des probabilités, on cherche à fournir
    un modèle mathématique pour une ``expérience aléatoire''.

    \begin{itemize}
        \item L'ensemble \(\Omega\) est appelé \defemph{univers}:
        il représente l'ensemble de toutes les éventualiés possibles,
        toutes les déterminations du hasard dans l'expérience considérée.
        Les éléments \(\omega\) de \(\Omega\), parfois appelés
        \defemph{événements élémentaires}, correspondent donc aux issues
        possibles de l'expérience aléatoire.

        \item La tribu \(\scr F\) correspond à l'ensemble des
        \defemph{événements}:  ce sont les parties de \(\Omega\) dont
        on peut évaluer la probabilité. Il faut voir un événement
        \(A\) de \(\scr F\) comme un sous-ensemble de \(\Omega\) 
        contenant toutes les éventualités \(\omega\) pour
        lesquelles une certaine propriété est vérifiée.

        \item On associe à chaque événement \(A\in\scr F\) un réel
        \(\bb P(A) \in \ff{0,1}\) qui donne la plausibilité que
        le résultat de l'expérience soit dans \(A\).
    \end{itemize}
\end{interp}

\subsubsection{Exemples d'espaces probabilisés}\label{subsubsec:1-2}
\setcounter{subsection}{0}
%\addcontentsline{toc}{subsubsection}{\nameref{subsubsec:2}}
Suivent quelques exemples classiques d'espaces probabilisés.

\begin{exs}[]
    cours a completer
\end{exs}


% ------------------------------------------------------------------------------------------
\subsection{Variables aléatoires}\label{subsec:2}

\subsubsection{Loi d'une variable aléatoire}\label{subsubsec:2-1}

\begin{definition}
    Soit \((\Omega, \scr F, \bb P)\) un espace probabilisé et \((E, \scr E)\) un espace mesurable. 
    Une \defemph{variable aléatoire} est une application
    \begin{equation*}
        X\colon \Omega \to E
    \end{equation*}
    mesurable. C'est-à-dire 
    \begin{equation*}
        \forall A\in\scr E, X^{-1}(A) = \{\omega\in\Omega\mid X(\omega)\in A\}\in\scr F
    \end{equation*}
    Si \(E = \R\) et \(\scr E = \scr B(\R)\), on parle de \defemph{variable aléatoire réelle}.

    Si \(E = \R^d\) et \(\scr E = \scr B(\R^d)\), on parle de \defemph{variable aléatoire vectorielle}.
\end{definition}

\begin{exs}\,\\
    \(\triangleright\) Lancer de deux dés.

    On considère l'expérience aléatoire qui consiste à lancer deux dés équilibrés. Alors
    \begin{equation*}
        \Omega = {\{1,\dots,6\}}^2,\quad \scr F = \scr P(\Omega).
    \end{equation*}
    On s'intéresse à la somme des résultats obtenus et on définit
    \begin{equation*}
        \begin{aligned}
            X\colon \Omega&\to \{2,\dots,12\}\\
            (i,j) &\mapsto i+j
        \end{aligned}
    \end{equation*}
    On munit l'ensemble d'arrivée de la tribu pleine.

    \(X\) est une variable aléatoire car l'espace de départ est muni de la tribu pleine.

    \(\triangleright\) Infinité de lancers d'un dé.

    On considère l'expérience aléatoire qui consiste à lancer un dé équilibré une infinité de fois. Alors
    \begin{equation*}
        \Omega = {\{1,\dots,6\}}^{\N^\ast} = \{\omega = {(\omega_n)}_{n\in\N^\ast}\mid \omega_n\in\{1,\dots,6\}\}
    \end{equation*}

    On considère la tribu \(\scr F\) la plus petite tribu contenant les \(A_{x_1,\dots,x_k}\). On s'intéresse
    au nombre de lancers jusqu'à l'apparition du premier 6. On définit
    \begin{equation*}
        \begin{aligned}
            Y\colon \Omega&\to \N^\ast\cup\{+\infty\}\\
            \omega ={{(\omega_n)}_{n\in\N^\ast}}&\mapsto \inf\{n\in\N^\ast\mid \omega_n = 6\}
        \end{aligned}
    \end{equation*}
    avec la convention \(\inf\emptyset = +\infty\). On munit l'ensemble d'arrivée de la tribu pleine.

    Pour \(k\geq 1\), on a
    \begin{equation*}
        \begin{aligned}
            Y^{-1}(\{k\}) 
            &= \{\omega={(\omega_n)}_{n\in\N^\ast}\mid \omega_1\ne 6,\dots,\omega_{k-1}\ne 6,\omega_k = 6\}\\
            &= \bigcup_{x_1,\dots,x_{k-1}\in\{1,\dots,5\}}A_{x_1,\dots,x_{k-1},6}\in\scr F
        \end{aligned}
    \end{equation*}

    Par ailleurs,
    \begin{equation*}
        \begin{aligned}
            Y^{-1}(\{+\infty\})
            &= \{\omega={(\omega_n)}_{n\in\N^\ast}\mid \forall n\in\N^\ast, \omega_n\ne 6\}\\
            &= \bigcap_{k=1}^{+\infty}\bigcup_{x_1,\dots,x_{k}\in\{1,\dots,5\}}A_{x_1,\dots,x_{k}}\in\scr F
        \end{aligned}
    \end{equation*}

    Comme \(\N\cup\{+\infty\}\) est dénombrable, on en déduit que \(Y\) est une variable aléatoire.

    \(\triangleright\) Bouteille à la mer.

    On considère l'expérience aléatoire qui consiste à observer la position d'une bouteille à la mer. Alors
    \begin{equation*}
        \Omega = \scr C^0(\ff{0,1},\R^2)
    \end{equation*}
    On considère la tribu \(\scr F\) la plus petite tribu rendant mesurables les applications coordonnées
    \begin{equation*}
        \begin{aligned}
            f_t\colon \Omega&\to \R^2\\
            \omega &\mapsto \omega(t)
        \end{aligned}
    \end{equation*}
    On s'intéresse à la position de la bouteille au temps \(t=1\). On définit
    \begin{equation*}
        \begin{aligned}
            Z\colon \Omega&\to \R^2\\
            \omega&\mapsto \omega(1)
        \end{aligned}
    \end{equation*}

    Alors, par construction de la tribu \(\scr F\), on a que \(Z\) est une variable aléatoire.
\end{exs}

\begin{definition}
    Soit \(X\) une variable aléatoire de \((\Omega, \scr F, \bb P)\) dans \((E, \scr E)\). La \defemph{loi} de \(X\) est la mesure
    image de \(X\) par \(\bb P\), définie par
    \begin{equation*}
        \forall A\in\scr E, \bb P_X(A) = \bb P(X^{-1}(A)) = \bb P(X\in A)
    \end{equation*}
\end{definition}

\begin{exs}[]\,\\
    \(\triangleright\) Infinité de lancers d'un dé.

    On considère
    \begin{equation*}
        \begin{aligned}
            Y\colon \Omega={\{1,\dots,6\}}^{\N^\ast}&\to \N^\ast\cup\{+\infty\}\\
            \omega={{(\omega_n)}_{n\in\N^\ast}}&\mapsto \inf\{n\in\N^\ast\mid \omega_n = 6\}
        \end{aligned}
    \end{equation*}
    La loi \(\bb P_Y\) de \(Y\) est une mesure de probabilité sur \(\N^\ast\cup\{+\infty\}\).

    Soit \(k\in\N^\ast\). On a
    \begin{equation*}
        \begin{aligned}
            \bb P_Y(\{k\}) 
            &= \bb P(Y^{-1}(\{k\}))\\
            &= \bb P(Y=k)\\
            &= \bb P\left(\bigcup_{x_1,\dots,x_{k-1}\in\{1,\dots,5\}}A_{x_1,\dots,x_{k-1},6}\right)\\
            &= \sum_{x_1,\dots,x_{k-1}} \underbrace{\bb P(A_{x_1,\dots,x_{k-1},6})}_{=\frac{1}{6^k}}\\
            &= \frac{5^{k-1}}{6^k}
            &= {\left(\frac{5}{6}\right)}^{k-1}\frac{1}{6}
        \end{aligned}
    \end{equation*}

    Par ailleurs, on a vu à la fin de la section précédente que
    la probabilité de ne jamais obtenir de 6 est nulle:
    \begin{equation*}
        \bb P_Y(\{+\infty\}) = \bb P(Y^{-1}(\{+\infty\})) = \bb P(Y=+\infty) = 0
    \end{equation*}
    On en déduit que la loi de \(Y\) est 
    \begin{equation*}
        \sum_{k=1}^{+\infty} {\left(\frac{5}{6}\right)}^{k-1}\frac{1}{6}\delta_k
    \end{equation*}
    Cette loi est appelée \defemph{loi géométrique} de paramètre \(\frac{5}{6}\).
\end{exs}

\begin{definition}[Variable aléatoire discrète]
    Une variable aléatoire \(X\) est dite \defemph{discrète} si \(X\) est à valeurs dans un ensemble \(E\) au plus dénombrable.
    On prend alors \(\scr E = \scr P(E)\) et si \(A\in\scr E\), on a
    \begin{equation*}
        \bb P_X(A) = \bb P(X\in A) = \bb P(X\in\cup_{x\in A}\{x\}) = \sum_{x\in A}\bb P(X=x)
    \end{equation*}

    La loi \(\bb P_X\) de \(X\) est alors entièrement déterminée par les quantités \(p_x = \bb P(X=x)\) pour tout \(x\in E\):
    \begin{equation*}
        \bb P_X(A) = \sum_{x\in E}p_x\delta_x
    \end{equation*}
\end{definition}

\begin{definition}[Variable aléatoire à densité]
    Une variable aléatoire \(X\) à valeurs dans \((\R^d, \scr B(\R^d))\) est dite \defemph{à densité} par rapport
    à la mesure de Lebesgue \(\lambda_d\) si il existe une fonction mesurable
    \begin{equation*}
        f\colon \R^d\to \fo{0,+\infty}
    \end{equation*}
    telle que \(\bb P_X = f\lambda_d\):
    \begin{equation*}
        \forall A\in\scr B(\R^d), \bb P_X(A) = \int_A f(x)\der\lambda_d(x)
    \end{equation*}
    Il faut que \(f\) vérifie
    \begin{equation*}
        \int_{\R^d}f(x)\der\lambda_d(x) = 1
    \end{equation*}
    Par exemple, si \(d=1\), on a
    \begin{equation*}
        \bb P_X\left(\ff{a,b}\right) = \int_a^b f(x)\der\lambda_1(x)
    \end{equation*}
    On notera souvent \(f_X = f\) et on appelle cette fonction la \defemph{densité} de \(X\).
\end{definition}

\subsubsection{Lois usuelles}\label{subsubsec:2-2}

% subsubsubsection ?

Lois discrètes:

Loi uniforme sur un ensemble fini \(\{x_1,\dots,x_n\}\).

Soit \(E = \{x_1,\dots,x_n\}\) un ensemble fini. 

Une variable aléatoire \(X\) suit une loi uniforme sur \(E\), notée \(X\sim\mathcal U(E)\), si sa loi est
\begin{equation*}
    \bb P_X = \frac{1}{n}\sum_{i=1}^n\delta_{x_i}
\end{equation*}
c'est-à-dire
\begin{equation*}
    \bb P_X(A) = \bb P(X\in A) = \frac{\text{card}(A)}{n}
\end{equation*}


Loi de Bernoulli.

Une variable aléatoire \(X\) suit une loi de Bernoulli de paramètre \(p\in\ff{0,1}\), notée \(X\sim\mathcal B(p)\), si sa loi est
\begin{equation*}
    \bb P_X = p\delta_1 + (1-p)\delta_0
\end{equation*}
c'est-à-dire
\begin{equation*}
    \bb P(X=1) = p,\quad \bb P(X=0) = 1-p
\end{equation*}


Loi binomiale.

Une variable aléatoire \(X\) suit une loi binomiale de paramètres \(n\in\N^\ast\) et \(p\in\ff{0,1}\), notée \(X\sim\mathcal B(n,p)\), si sa loi est
\begin{equation*}
    \bb P_X = \sum_{k=0}^n\binom{n}{k}p^k{(1-p)}^{n-k}\delta_k
\end{equation*}
cela correspond au nombre de succès dans \(n\) répétitions d'une expérience de Bernoulli de paramètre \(p\) (de manière indépendante).


Loi géométrique.

Une variable aléatoire \(X\) suit une loi géométrique de paramètre \(p\in\of{0,1}\), notée \(X\sim\mathcal G(p)\), si sa loi est
\begin{equation*}
    \bb P_X = \sum_{k=1}^{+\infty}p{(1-p)}^{k-1}\delta_k
\end{equation*}
c'est-à-dire
\begin{equation*}
    \bb P(X=k) = p{(1-p)}^{k-1}
\end{equation*}
cela correspond au nombre de répétitions d'une expérience de Bernoulli de paramètre \(p\) avant le premier succès.


Loi de Poisson.

Une variable aléatoire \(X\) suit une loi de Poisson de paramètre \(\theta>0\), notée \(X\sim\mathcal P(\theta)\), si sa loi est
\begin{equation*}
    \bb P_X = \sum_{k=0}^{+\infty}\frac{\theta^k}{k!}e^{-\theta}\delta_k
\end{equation*}
c'est-à-dire
\begin{equation*}
    \bb P(X=k) = \frac{\theta^k}{k!}e^{-\theta}
\end{equation*}
cela correspond au nombre d'événements rares dans un intervalle de temps donné.

% subsubsubsection 2? 

Lois à densité sur \(\R^d\):


Loi uniforme sur un ensemble \(A\) de \(\R^d\).

Soit \(A\in\scr B(\R^d)\), telle que \(0<\lambda_d(A)<+\infty\). 
Une variable aléatoire \(X\) suit une loi uniforme sur \(A\), notée \(X\sim\mathcal U(A)\), si sa loi est
\begin{equation*}
    \bb P_X = \frac{1}{\lambda_d(A)}\one_A
\end{equation*}
c'est-à-dire \(\bb P_X\) admet la densité constante \(\frac{1}{\lambda_d(A)}\one_A\). Autrement dit,
si \(B\in\scr B(\R^d)\), on a
\begin{equation*}
    \bb P_X(B) = \int_B \frac{1}{\lambda_d(A)}\one_A(x)\der\lambda_d(x) = \frac{\lambda_d(A\cap B)}{\lambda_d(A)}
\end{equation*}
dans le cas \(d=1\) et \(A = \ff{a,b}\), la densité est \(f(x) = \frac{\one_{\ff{a,b}}(x)}{b-a}\).


Loi exponentielle.

Une variable aléatoire \(X\) suit une loi exponentielle de paramètre \(\theta>0\), notée \(X\sim\mathcal E(\theta)\), si sa loi est
\begin{equation*}
    \bb P_X = \theta e^{-\theta x}\lambda_1\one_{\R^+}
\end{equation*}
c'est-à-dire \(\bb P_X\) admet la densité \(f_X(x)\theta e^{-\theta x}\one_{\R^+}\) par rapport à la mesure de Lebesgue \(\lambda_1\). Autrement dit,
si \(A\in\scr B(\R)\), on a
\begin{equation*}
    \bb P_X(A) = \int_A \theta e^{-\theta x}\one_{\R_+}(x)\der\lambda_1(x)
\end{equation*}
dans le cas \(d=1\). Cette loi vérifie la propriété de l'absence de mémoire, c'est-à-dire
\begin{equation*}
    \forall s,t\geq 0, \bb P(X>s+t\mid X>s) = \bb P(X>t)
\end{equation*}


Loi normale ou gaussienne.

Une variable aléatoire \(X\) suit une loi normale de paramètres \(\mu\in\R\) et \(\sigma>0\), notée \(X\sim\mathcal N(\mu,\sigma^2)\), si sa loi est
\begin{equation*}
    \bb P_X = f_X\lambda_1
\end{equation*}
où \(f_X\) est la densité de la loi normale, donnée par
\begin{equation*}
    f_X(x) = \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{{(x-\mu)}^2}{2\sigma^2}}
\end{equation*}
Autrement dit, si \(A\in\scr B(\R)\), on a
\begin{equation*}
    \bb P_X(A) = \int_A \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{{(x-\mu)}^2}{2\sigma^2}}\der\lambda_1(x)
\end{equation*}
remarque, la loi \(\cal N(0,1)\), c'est-à-dire avec la densité
\begin{equation*}
    f_X(x) = \frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}
\end{equation*}
est appelée loi normale standard.